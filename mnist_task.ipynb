{"cells":[{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_openml  # Use fetch_openml to load the MNIST dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\match\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["\n","# Load the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)  # Use fetch_openml to load the MNIST dataset\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\n","# Convert string labels to integers\n","mnist.target = mnist.target.astype(int)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\n","# Split the data into features (X) and labels (y)\n","X = mnist.data\n","y = mnist.target\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\n","# Split the data into training and test sets\n","# Add a comment explaining the purpose of the train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","# Purpose of the train and test sets: Training set is used to train the model, \n","# and the test set is used to evaluate the model's performance on unseen data.\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["\n","# Create a Random Forest Classifier\n","# Pick one parameter to tune, and explain why you chose this parameter\n","# Chosen parameter: n_estimators (number of trees in the forest)\n","# Explanation: Increasing the number of trees can improve the model's accuracy, but it also increases the computational cost.\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\n","# Choose a value for the parameter for testing on the test data and explain why\n","n_estimators_value = 100\n","# Chosen value: 100, a common default value that generally provides a good balance between accuracy and computational efficiency.\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["\n","# Initialize the Random Forest Classifier with the chosen parameter\n","rf_classifier = RandomForestClassifier(n_estimators=n_estimators_value, random_state=42)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"],"text/plain":["RandomForestClassifier(random_state=42)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Train the model on the training data\n","rf_classifier.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["\n","# Make predictions on the test data\n","y_pred = rf_classifier.predict(X_test)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n","[[1325    0    4    0    1    1    3    1    6    2]\n"," [   0 1573    6    8    2    0    0    6    3    2]\n"," [   4    5 1334    4    5    1    9    8    8    2]\n"," [   1    0   23 1366    0    9    0   14   12    8]\n"," [   4    1    3    0 1257    0    2    3    3   22]\n"," [   1    3    3   17    4 1226    8    1    8    2]\n"," [   4    1    0    0    6   10 1372    0    3    0]\n"," [   3    5   15    0    7    1    0 1455    2   15]\n"," [   1    6    9   15    6   11    5    7 1290    7]\n"," [   4    6    5   16   20    5    1   10    9 1344]]\n"]}],"source":["\n","# Print the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Metrics:\n","Accuracy: 0.9673\n","Precision: 0.9671\n","Recall: 0.9671\n","F1 Score: 0.9671\n"]}],"source":["# Report accuracy, precision, recall, and f1-score\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='macro')\n","recall = recall_score(y_test, y_pred, average='macro')\n","f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print(\"\\nMetrics:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Accuracy: 0.9673\n","\n","This represents the overall correctness of the model across all classes.\n","In this case, 96.73% of the predictions made by the model on the test set were correct.\n","Precision: 0.9671\n","\n","Precision is the ratio of correctly predicted positive observations to the total predicted positives.\n","A high precision value indicates that when the model predicts a certain class, it is usually correct.\n","In this case, on average, when the model predicts a positive instance, it is correct 96.71% of the time.\n","Recall: 0.9671\n","\n","Recall (Sensitivity or True Positive Rate) is the ratio of correctly predicted positive observations to the all observations in the actual class.\n","A high recall value indicates that the model is good at capturing all instances of a particular class.\n","In this case, on average, the model captures 96.71% of the true positive instances for each class.\n","F1 Score: 0.9671\n","\n","The F1 Score is the weighted average of precision and recall. It takes both false positives and false negatives into account.\n","A high F1 score indicates a good balance between precision and recall.\n","In this case, the F1 score is 96.71%, reflecting a good balance between precision and recall.\n","Overall, the model seems to perform well with high accuracy, precision, recall, and F1 score."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
